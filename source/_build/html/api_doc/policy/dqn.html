

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DQN &mdash; DI-engine 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Rainbow" href="rainbow.html" />
    <link rel="prev" title="Policy" href="index.html" />
    <link href="../../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> DI-engine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">使用者指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../installation/index_zh.html">安装说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/index_zh.html">快速上手</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro_rl/index_zh.html">强化学习基础概念介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hands_on/index.html">Hands on RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../env_tutorial/index_zh.html">强化学习环境示例手册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Doc</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../config/index.html">Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../env/index.html">Env</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Policy</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">DQN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dqnpolicy">DQNPolicy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="rainbow.html">Rainbow</a></li>
<li class="toctree-l3"><a class="reference internal" href="r2d2.html">R2D2</a></li>
<li class="toctree-l3"><a class="reference internal" href="a2c.html">A2C</a></li>
<li class="toctree-l3"><a class="reference internal" href="ddpg.html">DDPG</a></li>
<li class="toctree-l3"><a class="reference internal" href="qmix.html">QMIX</a></li>
<li class="toctree-l3"><a class="reference internal" href="coma.html">COMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="collaq.html">CollaQ</a></li>
<li class="toctree-l3"><a class="reference internal" href="ppg.html">PPG</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model/index.html">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reward_model/index.html">Reward Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../league/index.html">League</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worker/learner/index.html">Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worker/collector/index.html">Collector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worker/replay_buffer/index.html">Buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worker/coordinator/index.html">Coordinator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rl_utils/index.html">RL Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_utils/index.html">Torch Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html">Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../interaction/index.html">Interaction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index_zh.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../feature/index_zh.html">特性介绍</a></li>
</ul>
<p class="caption"><span class="caption-text">开发者指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../guide/index.html">开发者指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_dev/index.html">Tutorial-Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture/index.html">Architecture Design</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DI-engine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">API Doc</a> &raquo;</li>
        
          <li><a href="index.html">Policy</a> &raquo;</li>
        
      <li>DQN</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/api_doc/policy/dqn.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dqn">
<h1>DQN<a class="headerlink" href="#dqn" title="Permalink to this headline">¶</a></h1>
<div class="section" id="dqnpolicy">
<h2>DQNPolicy<a class="headerlink" href="#dqnpolicy" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.policy.dqn.</span></span><span class="sig-name descname"><span class="pre">DQNPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of DQN algorithm, extended by Double DQN/Dueling DQN/PER/multi-step TD.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>dqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>1,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>3</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequence of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._forward_collect">
<span class="sig-name descname"><span class="pre">_forward_collect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._forward_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of collect mode(collect training data), with eps_greedy for exploration.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
<li><p>eps (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): epsilon value for exploration, which is decayed by collected env step.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting policy_output(action) for the interaction with                 env and the constructing of transition.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">logit</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._forward_eval">
<span class="sig-name descname"><span class="pre">_forward_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._forward_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of eval mode(evaluate policy performance), at most cases, it is similar to             <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._forward_learn">
<span class="sig-name descname"><span class="pre">_forward_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._forward_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">value_gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">IS</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">priority</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">action_distribution</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._get_train_sample">
<span class="sig-name descname"><span class="pre">_get_train_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._get_train_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>For a given trajectory(transitions, a list of transition) data, process it into a list of sample that             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD)             or some continuous transitions(DRQN).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]</span></code>): The trajectory data(a list of transition), each element is the same                 format as the return value of <code class="docutils literal notranslate"><span class="pre">self._process_transition</span></code> method.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The list of training samples.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will vectorize <code class="docutils literal notranslate"><span class="pre">process_transition</span></code> and <code class="docutils literal notranslate"><span class="pre">get_train_sample</span></code> method in the following release version.             And the user can customize the this data processing procecure by overriding this two methods and collector             itself.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._init_collect">
<span class="sig-name descname"><span class="pre">_init_collect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._init_collect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize algorithm arguments and collect_model,             enable the eps_greedy_sample for exploration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._init_eval">
<span class="sig-name descname"><span class="pre">_init_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._init_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize eval_model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._init_learn">
<span class="sig-name descname"><span class="pre">_init_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._init_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize the optimizer, algorithm arguments, main             and target model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._load_state_dict_learn">
<span class="sig-name descname"><span class="pre">_load_state_dict_learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._load_state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._process_transition">
<span class="sig-name descname"><span class="pre">_process_transition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestep</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">collections.namedtuple</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._process_transition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate a transition(e.g.: &lt;s, a, s’, r, d&gt;) for this algorithm training.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation.</p></li>
<li><p>policy_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): The output of policy collect mode(<code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>),                including at least <code class="docutils literal notranslate"><span class="pre">action</span></code>.</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): The output after env step(execute policy output action), including at                 least <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code>, (here obs indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy._state_dict_learn">
<span class="sig-name descname"><span class="pre">_state_dict_learn</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy._state_dict_learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ding.policy.dqn.DQNPolicy.default_model">
<span class="sig-name descname"><span class="pre">default_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../_modules/ding/policy/dqn.html#DQNPolicy.default_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.policy.dqn.DQNPolicy.default_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demonstration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same inferface definition indicated             by import_names path. For DQN, <code class="docutils literal notranslate"><span class="pre">ding.model.template.q_learning.DQN</span></code></p>
</div>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="rainbow.html" class="btn btn-neutral float-right" title="Rainbow" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Policy" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>