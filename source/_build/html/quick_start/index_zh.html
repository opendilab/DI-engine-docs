

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>快速上手 &mdash; DI-engine 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Key Concept" href="../key_concept/index.html" />
    <link rel="prev" title="安装说明" href="../installation/index_zh.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DI-engine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">使用者指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/index_zh.html">安装说明</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">快速上手</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">构建运行时配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">初始化环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">设置策略和神经网络模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id8">定义执行模块</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">训练主循环</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id10">其他工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id11">可视化和日志</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index_zh.html">强化学习基础概念介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hands_on/index.html">Hands on RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_tutorial/index_zh.html">强化学习环境示例手册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index_zh.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature/index_zh.html">特性介绍</a></li>
</ul>
<p class="caption"><span class="caption-text">开发者指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">开发者指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture/index.html">Architecture Design</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DI-engine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>快速上手</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/quick_start/index_zh.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>快速上手<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<img alt="../_images/cartpole_cmp.gif" class="align-center" src="../_images/cartpole_cmp.gif" />
<p>首先，我们将说明如何使用 DI-engine 在简单的 <code class="docutils literal notranslate"><span class="pre">CartPole</span></code> 环境（如图所示）上运行 RL 实验。</p>
<p>具体来说，我们将在单个 python 文件中定义一整套训练逻辑，指定超参数、环境，神经网络和强化学习策略，以及主循环训练流程。</p>
<div class="section" id="id2">
<h2>构建运行时配置<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>构建训练工作流的第一步是指定训练配置。 DI-engine 推荐使用嵌套的 <cite>dict</cite> 对象来表示 RL 实验的所有参数和配置（<code class="docutils literal notranslate"><span class="pre">...</span></code> 表示省略的配置内容，完整的配置文件可以参考下面的路径），例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cartpole_dqn_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">exp_name</span><span class="o">=</span><span class="s2">&quot;cartpole_dqn&quot;</span><span class="p">,</span>
    <span class="n">env</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">collector_env_num</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">evaluator_env_num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">policy</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">encoder_hidden_size_list</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="o">...</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>具体内容可以参考：</p>
<blockquote>
<div><ul class="simple">
<li><p>配置文件:  <code class="docutils literal notranslate"><span class="pre">dizoo/classic_control/cartpole/config/cartpole_dqn_config.py</span></code></p></li>
<li><p>训练入口文件: <code class="docutils literal notranslate"><span class="pre">dizoo/classic_control/cartpole/entry/cartpole_dqn_main.py</span></code></p></li>
</ul>
</div></blockquote>
<p>输入下方命令即可运行实验：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3 -u dizoo/classic_control/cartpole/entry/cartpole_dqn_main.py
</pre></div>
</div>
</div>
<p>DI-engine 为所有模块提供默认配置，且有一个辅助函数 <code class="docutils literal notranslate"><span class="pre">compile_config</span></code> 合并各模块的默认配置和用户的自定义配置，从而产生具体训练运行的配置文件（最终的配置文件是一个 <code class="docutils literal notranslate"><span class="pre">EasyDict</span></code> 对象，可通过字符串键 <code class="docutils literal notranslate"><span class="pre">cfg[&quot;env&quot;]</span></code> 或 <code class="docutils literal notranslate"><span class="pre">cfg.env</span></code> 访问）：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ding.config</span> <span class="kn">import</span> <span class="n">compile_config</span>
<span class="kn">from</span> <span class="nn">ding.envs</span> <span class="kn">import</span> <span class="n">BaseEnvManager</span><span class="p">,</span> <span class="n">DingEnvWrapper</span>
<span class="kn">from</span> <span class="nn">ding.model</span> <span class="kn">import</span> <span class="n">DQN</span>
<span class="kn">from</span> <span class="nn">ding.policy</span> <span class="kn">import</span> <span class="n">DQNPolicy</span>
<span class="kn">from</span> <span class="nn">ding.worker</span> <span class="kn">import</span> <span class="n">BaseLearner</span><span class="p">,</span> <span class="n">SampleCollector</span><span class="p">,</span> <span class="n">BaseSerialEvaluator</span><span class="p">,</span> <span class="n">AdvancedReplayBuffer</span>
<span class="kn">from</span> <span class="nn">dizoo.classic_control.cartpole.config.cartpole_dqn_config</span> <span class="kn">import</span> <span class="n">cartpole_dqn_config</span>

<span class="c1"># compile config</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">compile_config</span><span class="p">(</span>
    <span class="n">cartpole_dqn_config</span><span class="p">,</span>
    <span class="n">BaseEnvManager</span><span class="p">,</span>
    <span class="n">DQNPolicy</span><span class="p">,</span>
    <span class="n">BaseLearner</span><span class="p">,</span>
    <span class="n">SampleCollector</span><span class="p">,</span>
    <span class="n">BaseSerialEvaluator</span><span class="p">,</span>
    <span class="n">AdvancedReplayBuffer</span><span class="p">,</span>
    <span class="n">save_cfg</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>这个例子中展示了在入口文件中指定配置的过程。在下一节中，我们根据指定的配置在同一个入口文件中构建 RL 训练流程。</p>
<p>请注意，DI-engine 还支持根据给定的配置文件直接运行 RL 实验，对应命令行如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ding -m serial -c cartpole_dqn_config.py -s <span class="m">0</span>
</pre></div>
</div>
<p>有关更多设计细节，请参阅 <a class="reference external" href="../key_concept/index.html#config">配置</a> 以及 <a class="reference external" href="../key_concept/index.html#entry">入口</a> 模块</p>
</div>
<div class="section" id="id5">
<h2>初始化环境<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>RL策略与环境交互以收集训练数据或测试其性能。DI-engine 继承广泛使用的 <a class="reference external" href="https://github.com/openai/gym">OpenAI Gym</a> RL 环境接口，并扩展了部分功能。您可以使用 <code class="docutils literal notranslate"><span class="pre">DingEnvWrapper</span></code> 将部分简单的 <code class="docutils literal notranslate"><span class="pre">gym</span></code> 环境
直接转化为DI-engine所需的格式。对于较复杂的环境，建议按照 <a class="reference external" href="../key_concept/index.html#env">环境</a> 部分中的指南构建具体的环境类。</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">Env</span> <span class="pre">Manager</span></code> 管理向量化的多个环境，一般使用python多进程实现。环境管理器的界面类似于简单的 <code class="docutils literal notranslate"><span class="pre">gym</span></code> 环境。这里我们展示一个使用 <code class="docutils literal notranslate"><span class="pre">BaseEnvManager</span></code> 来构建收集和评估环境的案例。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>

<span class="k">def</span> <span class="nf">wrapped_cartpole_env</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">DingEnvWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v0&#39;</span><span class="p">))</span>

<span class="n">collector_env_num</span><span class="p">,</span> <span class="n">evaluator_env_num</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">collector_env_num</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">evaluator_env_num</span>
<span class="n">collector_env</span> <span class="o">=</span> <span class="n">BaseEnvManager</span><span class="p">(</span><span class="n">env_fn</span><span class="o">=</span><span class="p">[</span><span class="n">wrapped_cartpole_env</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">collector_env_num</span><span class="p">)],</span> <span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">manager</span><span class="p">)</span>
<span class="n">evaluator_env</span> <span class="o">=</span> <span class="n">BaseEnvManager</span><span class="p">(</span><span class="n">env_fn</span><span class="o">=</span><span class="p">[</span><span class="n">wrapped_cartpole_env</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">evaluator_env_num</span><span class="p">)],</span> <span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">manager</span><span class="p">)</span>
</pre></div>
</div>
<p>设置常用库的环境的随机种子，保证实验的可复现性。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ding.utils</span> <span class="kn">import</span> <span class="n">set_pkg_seed</span>
<span class="c1"># Here we select a fixed seed in order to reach convergence more quickly for this demo</span>
<span class="c1"># Set seed for all package and instance</span>
<span class="n">collector_env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">evaluator_env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dynamic_seed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">set_pkg_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h2>设置策略和神经网络模型<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>DI-engine 支持 RL 训练中使用的大多数常用策略。每个都定义为一个 <code class="docutils literal notranslate"><span class="pre">Policy</span></code> class.</p>
<p>优化算法、数据预处理和后处理、神经网络的使用等细节都封装在 <code class="docutils literal notranslate"><span class="pre">Policy</span></code> 类之中。用户只需要构建一个 <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.Module.html">PyTorch 网络</a> （即继承于
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> ）并将其传入策略。</p>
<p>DI-engine 还提供一些默认的神经网络实现，以应用于较简单的环境。</p>
<p>例如，可以为 <code class="docutils literal notranslate"><span class="pre">CartPole</span></code> 环境定义如下的 <code class="docutils literal notranslate"><span class="pre">DQN</span></code> 神经网络和策略：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">DQNPolicy</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id8">
<h2>定义执行模块<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>DI-engine 需要构建一些执行组件来实际运行 RL 训练过程。<code class="docutils literal notranslate"><span class="pre">Collector</span></code> 用于收集训练所需的数据。<code class="docutils literal notranslate"><span class="pre">Learner</span></code> 用于接收数据并进行训练。<code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> 用于在需要的时候对策略进行评估。<code class="docutils literal notranslate"><span class="pre">Replay</span> <span class="pre">Buffer</span></code>
是一个存放数据的队列。对于不同算法，整个训练过程还可能需要其他组件。所有上述模块都可以通过配置自定义或由用户重写。</p>
<p>具体的创建过程如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">tensorboardX</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;./</span><span class="si">{}</span><span class="s1">/log/&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">exp_name</span><span class="p">),</span> <span class="s1">&#39;serial&#39;</span><span class="p">))</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">BaseLearner</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">learner</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">learn_mode</span><span class="p">,</span> <span class="n">tb_logger</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">exp_name</span><span class="p">)</span>
<span class="n">collector</span> <span class="o">=</span> <span class="n">SampleCollector</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">collector</span><span class="p">,</span> <span class="n">collector_env</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">collect_mode</span><span class="p">,</span> <span class="n">tb_logger</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">exp_name</span>
<span class="p">)</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">BaseSerialEvaluator</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">evaluator</span><span class="p">,</span> <span class="n">evaluator_env</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">eval_mode</span><span class="p">,</span> <span class="n">tb_logger</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">exp_name</span>
<span class="p">)</span>
<span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">AdvancedReplayBuffer</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">other</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="n">tb_logger</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">exp_name</span><span class="p">)</span>
</pre></div>
</div>
<p>这只是一组执行模块示例的具体设定。用户应根据需求自行选择需要的模块。</p>
</div>
<div class="section" id="id9">
<h2>训练主循环<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>DI-engine 中的训练循环可以任意定制。通常训练过程可能包括收集数据、更新策略和相关模块，评估策略性能。</p>
<p>在这里，我们提供了 <code class="docutils literal notranslate"><span class="pre">DQN</span></code> 针对 <code class="docutils literal notranslate"><span class="pre">CartPole</span></code> 环境的异策略训练示例。更多算法可以参考 <code class="docutils literal notranslate"><span class="pre">dizoo</span></code> 。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ding.rl_utils</span> <span class="kn">import</span> <span class="n">get_epsilon_greedy_fn</span>

<span class="c1"># DQN training loop</span>
<span class="n">eps_cfg</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">other</span><span class="o">.</span><span class="n">eps</span>
<span class="n">epsilon_greedy</span> <span class="o">=</span> <span class="n">get_epsilon_greedy_fn</span><span class="p">(</span><span class="n">eps_cfg</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">eps_cfg</span><span class="o">.</span><span class="n">end</span><span class="p">,</span> <span class="n">eps_cfg</span><span class="o">.</span><span class="n">decay</span><span class="p">,</span> <span class="n">eps_cfg</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
<span class="n">max_iterations</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">should_eval</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">train_iter</span><span class="p">):</span>
        <span class="n">stop</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">,</span> <span class="n">learner</span><span class="o">.</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">collector</span><span class="o">.</span><span class="n">envstep</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">stop</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">epsilon_greedy</span><span class="p">(</span><span class="n">collector</span><span class="o">.</span><span class="n">envstep</span><span class="p">)</span>
    <span class="n">new_data</span> <span class="o">=</span> <span class="n">collector</span><span class="o">.</span><span class="n">collect</span><span class="p">(</span><span class="n">train_iter</span><span class="o">=</span><span class="n">learner</span><span class="o">.</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">policy_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;eps&#39;</span><span class="p">:</span> <span class="n">eps</span><span class="p">})</span>
    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> <span class="n">cur_collector_envstep</span><span class="o">=</span><span class="n">collector</span><span class="o">.</span><span class="n">envstep</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">update_per_collect</span><span class="p">):</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">),</span> <span class="n">learner</span><span class="o">.</span><span class="n">train_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">train_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">learner</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">collector</span><span class="o">.</span><span class="n">envstep</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>您也可以参考完整的训练入口： dizoo/classic_control/cartpole/entry/cartpole_dqn_main.py。</p>
</div>
</div>
<div class="section" id="id10">
<h2>其他工具<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p>DI-engine 支持常见 RL 训练中的各种工具，如下所示。</p>
<div class="section" id="id11">
<h3>可视化和日志<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>某些环境具有渲染或可视化功能，DI-engine 没有使用渲染接口，而是添加了存储可视化结果 (replay) 的开关接口。如果想开启该功能，用户只需在入口函数训练主循环收敛后添加如下几行代码。如果一切正常，您可以在 <code class="docutils literal notranslate"><span class="pre">replay_path</span></code> 指定的文件夹中找到一些以 <code class="docutils literal notranslate"><span class="pre">.mp4</span></code> 为后缀的视频。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluator_env</span> <span class="o">=</span> <span class="n">BaseEnvManager</span><span class="p">(</span><span class="n">env_fn</span><span class="o">=</span><span class="p">[</span><span class="n">wrapped_cartpole_env</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">evaluator_env_num</span><span class="p">)],</span> <span class="n">cfg</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">manager</span><span class="p">)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">replay_path</span> <span class="o">=</span> <span class="s1">&#39;./video&#39;</span>  <span class="c1"># indicate save replay directory path</span>
<span class="n">evaluator_env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dynamic_seed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">evaluator_env</span><span class="o">.</span><span class="n">enable_save_replay</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">replay_path</span><span class="p">)</span>  <span class="c1"># switch save replay interface</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">BaseSerialEvaluator</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">evaluator</span><span class="p">,</span> <span class="n">evaluator_env</span><span class="p">,</span> <span class="n">policy</span><span class="o">.</span><span class="n">eval_mode</span><span class="p">,</span> <span class="n">tb_logger</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">exp_name</span>
<span class="p">)</span>
<span class="n">evaluator</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">,</span> <span class="n">learner</span><span class="o">.</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">collector</span><span class="o">.</span><span class="n">envstep</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果用户想使用之前已经训练好的策略来进行可视化，可以参照 <code class="docutils literal notranslate"><span class="pre">dizoo/classic_control/cartpole/entry/cartpole_dqn_eval.py</span></code> 构建一个自定义的评测入口函数，并在config中指定 <code class="docutils literal notranslate"><span class="pre">env.replay_path</span></code> and <code class="docutils literal notranslate"><span class="pre">policy.load_path</span></code> 两个字段，config示例如下面的代码所示，<code class="docutils literal notranslate"><span class="pre">...</span></code> 表示省略的config内容</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">env</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">replay_path</span><span class="o">=</span><span class="s1">&#39;your_replay_save_dir_path&#39;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">policy</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="n">load_path</span><span class="o">=</span><span class="s1">&#39;your_ckpt_path&#39;</span><span class="p">,</span>
        <span class="o">...</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>每个新的RL环境都可以自定义自己的 <code class="docutils literal notranslate"><span class="pre">enable_save_replay</span></code> 方法，指定具体生成回放文件的方式。DI-engine对于几个经典环境使用 <code class="docutils literal notranslate"><span class="pre">gym</span> <span class="pre">wrapper</span> <span class="pre">(内部调用ffmpeg)</span></code> 进行可视化。如果在使用 <code class="docutils literal notranslate"><span class="pre">gym</span> <span class="pre">wrapper</span></code> 录制视频时遇到一些错误，请尝试安装 <code class="docutils literal notranslate"><span class="pre">ffmpeg</span></code> 。</p>
</div>
<p>和其他深度强化学习平台类似，DI-engine也使用tensorboard来记录一些训练时的关键信息和参数。除了DI-engine默认记录
的信息之外，用户可以按照下文中的方式添加自己想记录的信息。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tb_logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;epsilon_greedy&#39;</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">learner</span><span class="o">.</span><span class="n">train_iter</span><span class="p">)</span>
</pre></div>
</div>
<p>如果你想了解DI-engine默认记录的参数信息的含义，可以参考DQN训练实验的 <a class="reference external" href="./tb_demo.html">tensorboard和日志demo</a> 。</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../key_concept/index.html" class="btn btn-neutral float-right" title="Key Concept" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../installation/index_zh.html" class="btn btn-neutral float-left" title="安装说明" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>